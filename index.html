<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Sentiment-analysis-on-movie-reviews by yuntuowang</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Sentiment-analysis-on-movie-reviews</h1>
        <h2></h2>
        <a href="https://github.com/yuntuowang/sentiment-analysis-on-movie-reviews" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="background-description" class="anchor" href="#background-description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background description</h1>

<p>Natural language processing (NLP) is an important field of computer science, and it is a significant research branch of data science. Speaking of the world we are living in recent years, we are surrounded with varieties of reviews which are helpful when we are making decisions. In this project, our goal is to benchmark our sentiment-analysis ideas on the Rotten Tomatoes movie review dataset. We are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive, which are corresponding to 0, 1, 2, 3, and 4 in the train.tsv file. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.</p>

<h1>
<a id="data-analysis" class="anchor" href="#data-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data analysis</h1>

<p>Here the dataset is the Rotten Tomatoes movie review, which is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee. Specifically, for train.tsv file, each record consists of four items, i.e., PhraseId, SentenceID, Phrase, and Sentiment. Corresponding to every sentence, there are all kinds of continuous phrase sequences(same SentenceID, incrementing PhraseIds). And 0 - 4 stands for the sentiment label in the sentiment column. And there are 156060 records in total. </p>

<p>For test.tsv file, each record consists of three items, i.e., PhraseId, SentenceID, and Phrase.  And there are 66293 records to be labeled in total. </p>

<h1>
<a id="method-analysis" class="anchor" href="#method-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Method analysis</h1>

<p>We decided to deeply analyze two methods, i.e., the Deep Learning for sentiment analysis from Stanford NLP Lab and the ordinary machine learning method(based on useful libraries and classifiers).</p>

<h3>
<a id="method1----based-on-machine-learning-libraries" class="anchor" href="#method1----based-on-machine-learning-libraries" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>Method1 -- based on machine learning libraries</em>
</h3>

<p>Our learning and modifications are based on: <a href="https://github.com/rafacarrascosa/samr/tree/develop/samr">here</a></p>

<p>The machine learning method package is based on <em>scikit-learn</em> and <em>nltk</em>. Basically, it contains a configuration file that is in JSON format, which determines how the <em>scikit-learn</em> pipeline is going to be built and other hyperparameters. We can adjust the classifier using and relevant arguments setting, which may bring better accuracy on the test data file. 
The predictor.py is the main module, and within it, the PhraseSentimentPredictor is the class that does the prediction and therefore one of the main entry points to the library.  A configurable main classifier is trained with the following two features: a. The decision functions use a one-versus-others scheme picking bag-of-words as features. It's a classifier inside a classifier. b. The amounts of "positive" and "negative" words in a phrase are dictated by the Harvard Inquirer sentiment lexicon. </p>

<p>Based on the current code, the valid values of the main classifier used are “sgd”(SGDClassifier), “knn”(KNeighborsClassifier), “svc”(SVC), and “randomforest”(RandomForestClassifier). Corresponding to each classifier, there is a dictionary to be passed as arguments. And we can also use other classifiers by importing them, as long as they have been implemented in scikit-learn library. </p>

<p>For example, let’s use “randomforest”, and the arguments are: {"n_estimators": 100, "min_samples_leaf":20, "n_jobs":-1}. 
“n_estimators” is the number of trees in the forest. The larger the better, but also the longer it will take to compute. But the results will stop getting significantly better beyond a critical number of trees. "min_samples_leaf" means the amount of samples for a leaf node, i.e. the trees are fully developed when its value is 1.  And we use “n_jobs” to denote the parallel construction of the trees. When “n_jobs” = k, computations are partitioned into k jobs, and run on k cores of the machine. If n_jobs=-1 then all cores available on the machine are used. </p>

<h3>
<a id="experiment-result" class="anchor" href="#experiment-result" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Experiment result</h3>

<p>You can see the details here: <a href="click%20me">https://docs.google.com/document/d/1RC7xrjuDkv20JhW36B17u6o3WgAalG7mtf9SO982FJI/edit?usp=sharing</a></p>

<h3>
<a id="method2----based-on-deep-learning" class="anchor" href="#method2----based-on-deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>Method2 -- based on deep learning</em>
</h3>

<h3>
<a id="background-description-1" class="anchor" href="#background-description-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background description</h3>

<p>The increasing popularity of Internet and social media exposed us to the massive information in our daily life. To make it more efficient to review the message and extract the useful data from it, message analysis can be a big topic to work on. Semantic word spaces or semantic vector spaces are used to represent the unit information when analysing the data. The sentences are divided into different semantic vector spaces and labeled with classes like negative and positive. However, this kind of method sometimes can’t yield ideal result since they ignore the order of each words. In that case, The Stanford Sentiment Treebank is developed to improve the overall accuracy in message analysis system. Based on the method we mentioned above, they still divided the sentence but they take the order of words into account and form a tree structure, which is more organized and turned out to have the best performance ever.</p>

<h3>
<a id="method-analysis-1" class="anchor" href="#method-analysis-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Method analysis</h3>

<ul>
<li><p>The treebank
The new Sentiment Treebank includes labels for every syntactically plausible phrase in thousands of sentences, which make it easier to train and evaluate compositional models. The dataset which the method uses includes 10662 sentences and half of them are positive and the other half are negative. They did much data pre-processing work to make sure that the training results can be more accurate. They deleted the label which are not English. They created a label interface to help them categorize each unit information. </p></li>
<li><p>Recursive Neural Models</p></li>
<li>RNN: Recursive Neural Network</li>
<li>The simplest member of this family of neural network models is the standard recursive neural network . For tree structure of RNN, it is determined that which parent has all their children calculated. Although RNN ignores the reconstruction loss, in practical experiment, the actual loss is small enough to be ignored.</li>
<li>MV-RNN: Matrix-Vector RNN</li>
<li>The main idea of the MV-RNN is to represent every word and longer phrase in a parse tree as both a vector and a matrix. When two constituents are combined, the matrix of one is multiplied with the vector of the other one, and vice versa. In this model, each word’s matrix is initialized as a d×d identity matrix, plus a small amount of Gaussian noise, where the parameter can contribute to less error.</li>
<li>RNTN:Recursive Neural Tensor Network</li>
<li><p>To solve the problem of increasing number of parameters concerning the MV-RNN models and the single interaction with input vectors concerning the RNN, RNTN is invented. The main idea is to use the same, tensor-based composition function for all nodes.</p></li>
<li><p>Experiment
Their test analysis can be divided into two steps. One is the analysis focusing on the data set, and the other one is the analysis based on two linguistic phenomena that are important in sentiment.</p></li>
<li>They used fine-grained sentiment for all phrases and binary sentiment. The results they got showed that the new treebank structure remarkably improved the overall accuracy. </li>
<li>They then analyzed the different models focusing on Contrastive Conjunction, High Level Negation and Most Positive and Negative Phrases. Those are all common linguistic phenomena we can see in our daily life. The sub-dataset building and testing using different models are talked above.</li>
</ul>

<h3>
<a id="demo-results" class="anchor" href="#demo-results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo results</h3>

<p><a href="https://docs.google.com/document/d/1RC7xrjuDkv20JhW36B17u6o3WgAalG7mtf9SO982FJI/edit?usp=sharing">click here for details</a></p>

<h3>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusion</h3>

<p>Overall, this method introduced a brand new structure (Stanford treebank) to the sentiment analysis field. It pushed the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines.</p>

<h1>
<a id="comparison-of-two-methods-and-reflection" class="anchor" href="#comparison-of-two-methods-and-reflection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Comparison of two methods and reflection</h1>

<p>The first method is based on relatively mature machine learning package, using different classifiers to label the sentiments. As far as we have experimented, the accuracy is less than 70%. However, since it is based on popular and mature ML packages, it is easier to understand and use in practical. </p>

<p>The second deep learning method brings the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases. The achievement of this method inspired us to think things differently especially when we consider the data we want to input. A new way to process the data can bring new idea of algorithm and probable improvement overall.</p>

<h1>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h1>

<p>This project is maintained by Yuntuo Wang, and you can search username "yuntuowang" on Github. If you get any concerns or questions, feel free to contact me. </p>

<p><em>Contact info:</em> </p>

<ul>
<li>Yuntuo Wang       <a href="mailto:yuntuowang2015@u.northwestern.edu">yuntuowang2015@u.northwestern.edu</a>
</li>
<li>Peiyu Wang        <a href="mailto:peiyuwang2016@u.northwestern.edu">peiyuwang2016@u.northwestern.edu</a>
</li>
</ul>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/yuntuowang/sentiment-analysis-on-movie-reviews/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/yuntuowang/sentiment-analysis-on-movie-reviews/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/yuntuowang/sentiment-analysis-on-movie-reviews"></a> is maintained by <a href="https://github.com/yuntuowang">yuntuowang</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
